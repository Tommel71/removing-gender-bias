{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Training a low gender-bias model from unfair data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Imports"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Parameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# main variable to change, use the method of using the gender variable to make the model ignore the predictors for the gender\n",
    "bake_in_bias = True\n",
    "cutoff = 2\n",
    "# set numpy seed\n",
    "np.random.seed(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Convention for naming classes: female: 0, male: 1, can also be read as: unbiased: 0 or biased: 1\n",
    "I call the variable often latent variable, but its actually an attribute in the data, so it is not latent\n",
    "But if we can make the model ignore this fake latent variable, it should also be able to ignore a real latent variable\n",
    "Be careful with the gender variables: There are 3 different ones. The latent gender variable,\n",
    "the gender variable in the data which we can change to control the outcome and the actual gender\n",
    "The latent gender variable is always the same as the actual gender variable here."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Functions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def analyse_classification(y_pred, x_val, y_val, gender_val):\n",
    "    df = pd.DataFrame(x_val)\n",
    "    df.columns = [\"score1\", \"score2\", \"latent_variable\", \"gender_variable\"]\n",
    "    df = pd.concat([df, pd.DataFrame({\"prediction\": y_pred > 0, \"actual\": list(map(bool, y_val)), \"gender\": gender_val})],axis=1)\n",
    "    df[\"TP\"] = df[\"prediction\"] & df[\"actual\"]\n",
    "    df[\"TN\"] = ~df[\"prediction\"] & ~df[\"actual\"]\n",
    "    df[\"FP\"] = df[\"prediction\"] & ~df[\"actual\"]\n",
    "    df[\"FN\"] = ~df[\"prediction\"] & df[\"actual\"]\n",
    "    agg = df.groupby(\"gender\").sum()\n",
    "    agg.index = [\"female\", \"male\"]\n",
    "    print(agg)\n",
    "    winners = df[y_pred> 0]\n",
    "    print(winners)\n",
    "    means = winners.groupby(\"gender\").mean().iloc[:,:2].sum(axis= 1)\n",
    "\n",
    "    return means[0], means[1]\n",
    "\n",
    "# now for validating this approach we create the same data but this time balanced\n",
    "def eval(x_val, y_val, gender_val):\n",
    "    y_pred = net(x_val).detach().numpy()\n",
    "    print(\"accuracy: \", ((y_pred > 0) == y_val.detach().numpy()).sum().item() / len(y_val))\n",
    "    return analyse_classification(y_pred, x_val, y_val, gender_val)\n",
    "\n",
    "def create_data(n_data=100000, unfairness=0, only_male=False, only_female=False):\n",
    "    print(\"Generate data...\")\n",
    "    # generate random data\n",
    "    x = np.random.randn(n_data, 2)\n",
    "    # sample 90% male and 10% female\n",
    "    gender = np.random.choice([0, 1], size=n_data, p=[0.5, 0.5]).astype(float)\n",
    "    gender_for_model = gender\n",
    "\n",
    "    if only_male:\n",
    "        gender_for_model = np.ones(n_data)\n",
    "\n",
    "    if only_female:\n",
    "        gender_for_model = np.zeros(n_data)\n",
    "\n",
    "    assert not (only_male and only_female)\n",
    "    # convert gender to float\n",
    "\n",
    "    # concatenate gender to the data\n",
    "    # think of x without the gender as scores in a test and then add unfairness with the gender variable.\n",
    "    y = np.array([1 if sum(x[i,:]) > cutoff - gender[i]* unfairness else 0 for i in range(len(x))])\n",
    "\n",
    "    latent_gender = gender\n",
    "    # concatenate latent information, we cant manipulate this, this is in the data\n",
    "    # this is even stronger than just a latent variable that is learned, this does not have to be learned\n",
    "    # it is provided as an attribute, so even easier for the model to exploit\n",
    "    # The goal is to make the model ignore this. If we can do that we can also do it with a latent variable\n",
    "    x = np.concatenate((x, latent_gender.reshape(-1, 1)), axis=1)\n",
    "\n",
    "\n",
    "    x = np.concatenate((x, gender_for_model.reshape(-1, 1)), axis=1) # concatenate gender information that we can manipulate\n",
    "\n",
    "    # undersample the majority class\n",
    "    mask_accepted = y == 1\n",
    "    mask_male = gender == 1\n",
    "\n",
    "\n",
    "\n",
    "    mask_accepted_and_male = mask_accepted & mask_male\n",
    "    mask_accepted_and_female = mask_accepted & ~mask_male\n",
    "    mask_not_accepted_and_male = ~mask_accepted & mask_male\n",
    "    mask_not_accepted_and_female = ~mask_accepted & ~mask_male\n",
    "    minimal_data = 1000 # very ugly and hacky\n",
    "\n",
    "    def get_balanced_data(data):\n",
    "        return np.concatenate([data[mask_accepted_and_male][:minimal_data],\n",
    "                               data[mask_accepted_and_female][:minimal_data],\n",
    "                               data[mask_not_accepted_and_male][:minimal_data],\n",
    "                               data[mask_not_accepted_and_female][:minimal_data]])\n",
    "    # balance data\n",
    "    x = get_balanced_data(x)\n",
    "    y = get_balanced_data(y)\n",
    "    gender = get_balanced_data(gender)\n",
    "\n",
    "\n",
    "    # get a permutation of the data\n",
    "    perm = np.random.permutation(4*minimal_data)\n",
    "    x = x[perm]\n",
    "    y = y[perm]\n",
    "    gender = gender[perm]\n",
    "\n",
    "    print(y.sum() / (4*minimal_data) * 100, \"% class 2 samples\")\n",
    "\n",
    "    # convert x and y to tensors\n",
    "    x = torch.from_numpy(x).float()\n",
    "    y = torch.from_numpy(y).float()\n",
    "    return x, y, gender\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define experiment setting"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "k_reps = 10"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Run experiment"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "differences_meanscore_bake = []\n",
    "differences_meanscore_nobake =[]\n",
    "accuracies_bake = []\n",
    "accuracies_nobake = []\n",
    "\n",
    "for i in range(k_reps):\n",
    "    for bake_in_bias in [True, False]:\n",
    "\n",
    "        x,y, gender = create_data(unfairness=1)\n",
    "        n = len(x)\n",
    "        # split train test data\n",
    "        x_train = x[:int(n*0.8)]\n",
    "        y_train = y[:int(n*0.8)]\n",
    "        x_test = x[int(n*0.8):]\n",
    "        y_test = y[int(n*0.8):]\n",
    "        gender_train = gender[:int(n*0.8)]\n",
    "        gender_test = gender[int(n*0.8):]\n",
    "\n",
    "        # create a neural network where the last variable jumps to the last layer\n",
    "\n",
    "        n_attributes = x.shape[1]\n",
    "        # create a neural network\n",
    "        class Net(nn.Module):\n",
    "            def __init__(self, erased_last_var=False):\n",
    "                super(Net, self).__init__()\n",
    "                self.erased_last_var = erased_last_var\n",
    "                self.fc1 = nn.Linear(n_attributes  - int(erased_last_var) , 5)\n",
    "                self.fc2 = nn.Linear(5, 3)\n",
    "                self.fc3 = nn.Linear(3, 1)\n",
    "\n",
    "\n",
    "            def forward(self, x):\n",
    "                # cut off last variable\n",
    "                x_last = x[:, -1]\n",
    "                x_rest = x[:, :-1]\n",
    "\n",
    "                if not self.erased_last_var:\n",
    "                    # right before the last layer we add the last variable, to make it have a strong effect on the output\n",
    "                    x = x\n",
    "                else:\n",
    "                    x = x_rest\n",
    "\n",
    "                x = self.fc1(x)\n",
    "                x = self.fc2(x)\n",
    "                x = self.fc3(x)\n",
    "\n",
    "                # remove last dimension\n",
    "                x = x.reshape(-1)\n",
    "                return x\n",
    "\n",
    "        net = Net(erased_last_var=(not bake_in_bias)) # if we are not baking in the bias we are not using that last variable\n",
    "\n",
    "        # create optimizer use adam\n",
    "        optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "        # training the network but freezing all the weights in the first layer except for the gender variable\n",
    "\n",
    "        for epoch in range(3000):\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            out = net(x_train)\n",
    "            loss = F.binary_cross_entropy_with_logits(out, y_train)\n",
    "            loss.backward()\n",
    "            if bake_in_bias:\n",
    "                # set gradients to zero so that there is more signal for the last variable:\n",
    "                for n, w in net.named_parameters():\n",
    "                    if n == \"fc1.weight\":\n",
    "                        w.grad[:,:-1] = 0\n",
    "                    if n == \"fc1.bias\":\n",
    "                        w.grad[:-1] = 0\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "        for epoch in range(3000):\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            out = net(x_train)\n",
    "            loss = F.binary_cross_entropy_with_logits(out, y_train)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "        print(50*\"*\")\n",
    "        print(\"Performance on test set (unfair), not so interesting, just to check if the model works well on similar data it was trained on\")\n",
    "        eval(x_test, y_test, gender_test)\n",
    "\n",
    "        # the only_female gender labels do not have any effect on the model without baking because that one\n",
    "        # drops the last variable as defined above\n",
    "        x_val_fair, y_val_fair, gender_val_fair = create_data(unfairness=0, only_female=True)\n",
    "        print(50*\"*\")\n",
    "        print(\"Now on fair evaluation data with all genders set to female on the gender variable (latent variable still contains real gender information):\")\n",
    "        means = eval(x_val_fair, y_val_fair, gender_val_fair)\n",
    "        print(\"Mean score of person getting accepted, should be very similar for both classes otherwise there is bias because one class gets in with a lower score on average\")\n",
    "        print(f\"Mean score of female getting accepted: {means[0]}, \\nMean score of male   getting accepted: {means[1]}\")\n",
    "        print(\"If the model used the latent variable, it would not perform well on fair data and the means would differ (more)\")\n",
    "\n",
    "        x_val_fair, y_val_fair, gender_val_fair = create_data(unfairness=0, only_female=True)\n",
    "        eval(x_val_fair, y_val_fair, gender_val_fair)\n",
    "        x_val_fair_male = x_val_fair.clone()\n",
    "        x_val_fair_male[:, -1] = 1\n",
    "        eval(x_val_fair_male, y_val_fair, gender_val_fair)\n",
    "        x_val_fair_female = x_val_fair.clone()\n",
    "        # combine male and female predictions\n",
    "\n",
    "        y_pred_female = net(x_val_fair_female).detach().numpy()\n",
    "        y_pred_male = net(x_val_fair_male).detach().numpy()\n",
    "        merged_pred = y_pred_female + y_pred_male\n",
    "        means = analyse_classification(merged_pred, x_val_fair, y_val_fair, gender_val_fair)\n",
    "\n",
    "        if bake_in_bias:\n",
    "            differences_meanscore_bake.append(means[0] - means[1])\n",
    "            accuracies_bake.append(((merged_pred > 0) == y_val_fair.numpy()).mean())\n",
    "        else:\n",
    "            differences_meanscore_nobake.append(means[0] - means[1])\n",
    "            accuracies_nobake.append(((merged_pred > 0) == y_val_fair.numpy()).mean())\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plotting"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.DataFrame({\"bake\": differences_meanscore_bake, \"nobake\": differences_meanscore_nobake}).plot(kind=\"line\", title=\"Differences in mean score of accepted applicants\")\n",
    "# add zero horizontal line\n",
    "plt.axhline(0, color=\"black\")\n",
    "plt.show()\n",
    "\n",
    "pd.DataFrame({\"bake\": accuracies_bake, \"nobake\": accuracies_nobake}).plot(kind=\"line\", title=\"Accuracy of model on fair data, predicting if candidate is admitted\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Almost 100% sure that it is not the baking that helps with the bias, but just the use of the variable while training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}